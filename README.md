
# bigdata-env

åŸºäº Docker Compose éƒ¨ç½²å¤§æ•°æ®å¼€å‘ç¯å¢ƒï¼Œé›†æˆäº† Sparkã€Hadoopã€Hive å’Œ JupyterLabã€‚

## ğŸ“‹ ç¯å¢ƒè¦æ±‚

### ç³»ç»Ÿè¦æ±‚

- Docker 20.10+
- Docker Compose 2.0+
- è‡³å°‘ 8GB å†…å­˜
- è‡³å°‘ 20GB å¯ç”¨ç£ç›˜ç©ºé—´

### å¹³å°æ”¯æŒ

- [x] macOS (Intel/Apple Silicon)
- [x] Linux (x86_64)
- [x] Windows (WSL2)

## ğŸ—ï¸ æ¶æ„è¯´æ˜

### æœåŠ¡ç»„ä»¶
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Spark Master    â”‚   â”‚  Spark Worker 1  â”‚   â”‚  Spark Worker 2  â”‚
â”‚   (Master Node)   â”‚   â”‚  (Worker Node)   â”‚   â”‚  (Worker Node)   â”‚
â”‚                   â”‚   â”‚                  â”‚   â”‚                  â”‚
â”‚ â€¢ Spark Master    â”‚   â”‚ â€¢ Spark Worker   â”‚   â”‚ â€¢ Spark Worker   â”‚
â”‚ â€¢ Hadoop NameNode â”‚   â”‚ â€¢ Hadoop DataNodeâ”‚   â”‚ â€¢ Hadoop DataNodeâ”‚
â”‚ â€¢ YARN ResourceMgrâ”‚   â”‚ â€¢ YARN NodeMgr   â”‚   â”‚ â€¢ YARN NodeMgr   â”‚
â”‚ â€¢ Hive Metastore  â”‚   â”‚                  â”‚   â”‚                  â”‚
â”‚ â€¢ JupyterLab      â”‚   â”‚                  â”‚   â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                       â”‚                       â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚       MySQL        â”‚
                        â”‚ (Metadata Storage) â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ç«¯å£æ˜ å°„

| æœåŠ¡ | ç«¯å£ | è¯´æ˜ |
|------|------|------|
| Spark Master Web UI | [8080](http://localhost:8080) | Spark é›†ç¾¤ç®¡ç†ç•Œé¢ |
| Hadoop NameNode | [9870](http://localhost:9870) | HDFS ç®¡ç†ç•Œé¢ |
| YARN ResourceManager | [8088](http://localhost:8088) | YARN èµ„æºç®¡ç†ç•Œé¢ |
| JupyterLab | [8888](http://localhost:8888) | äº¤äº’å¼å¼€å‘ç¯å¢ƒ |
| Hive Metastore | 9083 | Hive å…ƒæ•°æ®æœåŠ¡ |
| HiveServer2 | 10000 | Hive JDBC/ODBC æœåŠ¡ |
| Hadoop History Server | 19888 | MapReduce å†å²æœåŠ¡å™¨ |
| YARN NodeManager | 8042 | YARN èŠ‚ç‚¹ç®¡ç†ç•Œé¢ |
| Spark Application UI | 4040 | Spark åº”ç”¨ç›‘æ§ç•Œé¢ |
| MySQL | 3306 | æ•°æ®åº“æœåŠ¡ |

## ğŸ› ï¸ æœ¬åœ°å®‰è£…

> [!WARNING]
>
> 1. `hive-site.xml` ä¸ `docker-compose.yml` å¯èƒ½åŒ…å«æ˜æ–‡å¯†ç ï¼Œè¯·å‹¿å°†åŒ…å«å¯†ç çš„æ–‡ä»¶æ¨é€è‡³å…¬ç½‘ä»“åº“
> 2. æœ¬é¡¹ç›®å¯†ç ä»…ä½œç¤ºä¾‹ä¹‹ç”¨ï¼Œè¯·å‹¿åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨

### 1. å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/luochang212/bigdata-env.git
cd bigdata-env
```

### 2. é…ç½® `.env` æ–‡ä»¶

å¤åˆ¶ `.env` æ–‡ä»¶æ¨¡ç‰ˆï¼Œåˆ›å»ºä½ çš„ `.env` æ–‡ä»¶ï¼š

```bash
cp .env.example .env
```

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œæ›´æ–°å¯†ç ï¼ˆå¯é€‰ï¼‰ï¼š

```bash
MYSQL_ROOT_PASSWORD=[your-mysql-root-password]
MYSQL_PASSWORD=[your-mysql-password]
HIVE_DB_PASSWORD=[your-hive-db-password]
```

### 3. æ„å»ºå’Œå¯åŠ¨æœåŠ¡

```bash
# å¯¹äº Windows ç”¨æˆ·ï¼Œéœ€è¦è½¬æ¢ä¸º Unix æ¢è¡Œç¬¦
# Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
# .\convert.ps1

# æ„å»ºé•œåƒï¼ˆé¦–æ¬¡è¿è¡Œæˆ–æ›´æ–° Dockerfile åï¼‰
docker compose build --no-cache

# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker compose up -d

# åœæ­¢å¹¶åˆ é™¤æ‰€æœ‰æœåŠ¡
docker compose down -v --rmi local
```

### 4. éªŒè¯æœåŠ¡çŠ¶æ€

```bash
# æ£€æŸ¥å®¹å™¨çŠ¶æ€
docker compose ps

# æŸ¥çœ‹æœåŠ¡æ—¥å¿—
docker compose logs -f
```

### 5. éªŒè¯ Hive è¿æ¥

```bash
docker exec -it spark-hadoop-hive-master hive -e 'SHOW DATABASES;'
```

### 6. è·å– JupyterLab Token

JupyterLab åœ°å€ï¼š[http://localhost:8888/lab](http://localhost:8888/lab)

è¿›å…¥ master èŠ‚ç‚¹å®¹å™¨ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤è·å–è®¿é—®ä»¤ç‰Œï¼š

```bash
docker exec -it spark-hadoop-hive-master /opt/miniconda3/bin/jupyter lab list
```

è¿›å…¥ JupyterLab åï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ Hive å’Œ Sparkï¼š

```bash
# éªŒè¯ Hive æœåŠ¡å¯ç”¨
hive -e 'SHOW DATABASES;'

# ç¡®è®¤ Spark æœåŠ¡å¯ç”¨
pyspark

# ä¹Ÿå¯å¯åŠ¨ Spark äº¤äº’å¼å‘½ä»¤è¡Œ
spark-shell
```

<!-- ## ğŸ“ é¡¹ç›®ç»“æ„

```
bigdata-env/
â”œâ”€â”€ .env.example              # ç¯å¢ƒå˜é‡æ¨¡æ¿
â”œâ”€â”€ .gitignore               # Git å¿½ç•¥æ–‡ä»¶
â”œâ”€â”€ Dockerfile               # é•œåƒæ„å»ºæ–‡ä»¶
â”œâ”€â”€ README.md                # é¡¹ç›®è¯´æ˜æ–‡æ¡£
â”œâ”€â”€ docker-compose.yml       # æœåŠ¡ç¼–æ’æ–‡ä»¶
â”œâ”€â”€ docs.md                  # è¯¦ç»†æ–‡æ¡£
â”œâ”€â”€ config/                  # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ core-site.xml       # Hadoop æ ¸å¿ƒé…ç½®
â”‚   â”œâ”€â”€ hadoop-env.sh       # Hadoop ç¯å¢ƒå˜é‡
â”‚   â”œâ”€â”€ hdfs-site.xml       # HDFS é…ç½®
â”‚   â”œâ”€â”€ hive-site.xml       # Hive é…ç½®
â”‚   â”œâ”€â”€ mapred-site.xml     # MapReduce é…ç½®
â”‚   â”œâ”€â”€ ssh_config          # SSH é…ç½®
â”‚   â”œâ”€â”€ workers             # Worker èŠ‚ç‚¹åˆ—è¡¨
â”‚   â””â”€â”€ yarn-site.xml       # YARN é…ç½®
â”œâ”€â”€ share/                   # å…±äº«æ•°æ®ç›®å½•
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ start-master.sh          # ä¸»èŠ‚ç‚¹å¯åŠ¨è„šæœ¬
â”œâ”€â”€ start-worker.sh          # å·¥ä½œèŠ‚ç‚¹å¯åŠ¨è„šæœ¬
â””â”€â”€ archived/                # å†å²ç‰ˆæœ¬å­˜æ¡£
    â”œâ”€â”€ 1-spark/
    â”œâ”€â”€ 2-spark-hadoop/
    â”œâ”€â”€ 3-spark-hadoop-hive/
    â””â”€â”€ 4-spark-hadoop-hive-jupyterlab/
``` -->

## ğŸ“š å‚è€ƒèµ„æ–™

- [ä½¿ç”¨ Docker å¿«é€Ÿéƒ¨ç½² Spark + Hadoop å¤§æ•°æ®é›†ç¾¤](https://s1mple.cc/2021/10/12/%E4%BD%BF%E7%94%A8-Docker-%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2-Spark-Hadoop-%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BE%A4/)

## ğŸ“ Vibe Coding

å£°æ˜ï¼šæœ¬é¡¹ç›®ä½¿ç”¨ [Trae AI](https://trae.ai) è¾…åŠ©å¼€å‘ã€‚
